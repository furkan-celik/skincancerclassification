{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS412 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J7CujHbwVQX3"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furkan-celik/skincancerclassification/blob/master/CS412_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFo4pCdV1t50",
        "colab_type": "text"
      },
      "source": [
        "### Make sure GPU is on\n",
        "\n",
        "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7YbBoUR5NVj",
        "colab_type": "text"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtRngMsHc-Ko",
        "colab_type": "code",
        "outputId": "8077279d-300e-4d6e-8952-c4060bf44092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYLq3bbYHNy6",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-4gka21hVl",
        "colab_type": "code",
        "outputId": "e475af42-b3dd-4a58-b351-b8178ab638c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2D-1er639_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow_addons import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CujHbwVQX3",
        "colab_type": "text"
      },
      "source": [
        "#To seperate images to folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWgzFoBCv3z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "folder = '/content/drive/My Drive/CS412/ImageAugmention/4'\n",
        "for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj4XnzbeC7lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC_PATH = \"/content/drive/My Drive/CS412/Data_SkinCancer/\"\n",
        "DST_PATH_TRAIN = '/content/drive/My Drive/CS412/DatasByFolder/'\n",
        "i = 0\n",
        "for index, row in traincsv.iterrows():\n",
        "  i += 1\n",
        "  FILE_PATH = SRC_PATH + row[\"Id\"] + \".jpg\"\n",
        "  FOLDER_PATH_TRAIN = DST_PATH_TRAIN + str(row[\"Category\"]) + \"/\"\n",
        "  if(not os.path.exists(FOLDER_PATH_TRAIN)):\n",
        "    os.mkdir(FOLDER_PATH_TRAIN)\n",
        "  shutil.copy(FILE_PATH, FOLDER_PATH_TRAIN + row[\"Id\"] + \".jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdzpzCwnqlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAIN_PATH = \"/content/drive/My Drive/CS412/Data_SkinCancer/\"\n",
        "os.mkdir(MAIN_PATH + \"TestData/\")\n",
        "for index, row in testcsv.iterrows():\n",
        "  FILE_PATH = MAIN_PATH + row[\"Id\"] + \".jpg\"\n",
        "  FOLDER_PATH = MAIN_PATH + \"TestData/\" + str(row[\"Category\"]) + \"/\"\n",
        "  if(not os.path.exists(FOLDER_PATH)):\n",
        "    os.mkdir(FOLDER_PATH)\n",
        "  shutil.copy(FILE_PATH, FOLDER_PATH + row[\"Id\"] + \".jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZxPj4jnuZjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DST_PATH_TRAIN = '/content/drive/My Drive/CS412/DatasByFolder/'\n",
        "for index in range(0, len(traincsv)):\n",
        "  if type(traincsv[\"Id\"][index]) == str and traincsv[\"Id\"][index].find(\"Image\") != -1:\n",
        "    FILE_PATH = DST_PATH_TRAIN + str(traincsv[\"Category\"][index]) + \"/\" + traincsv[\"Id\"][index] + \".jpg\"\n",
        "    img = cv2.imread(FILE_PATH)\n",
        "    traincsv[\"Id\"][index] = img\n",
        "    del img\n",
        "    print(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzS9Y2yhar1O",
        "colab_type": "code",
        "outputId": "d1245f82-fd6c-4d4f-c7fa-9651bc278c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "SRC_PATH = \"/content/drive/My Drive/CS412/Data_SkinCancer/\"\n",
        "DST_PATH_TRAIN = '/content/drive/My Drive/CS412/DatasByFolder/'\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rotation_range=135,\n",
        "  width_shift_range=0.4,\n",
        "  height_shift_range=0.4,\n",
        "  shear_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest') # set validation split\n",
        "\n",
        "for index, row in traincsv.groupby(\"Category\").get_group(\"4\").iterrows():\n",
        "  saveDir = '/content/drive/My Drive/CS412/ImageAugmention/4/' + str(row[\"Id\"][:len(row[\"Id\"]) - 4])\n",
        "  if(not os.path.exists(saveDir)):\n",
        "    os.mkdir(saveDir)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_dataframe(\n",
        "          pd.DataFrame({\"Id\": row[\"Id\"], \"Category\": row[\"Category\"]}, index=[\"Id\"]),  # This is the source directory for training images\n",
        "          directory=\"/content/drive/My Drive/CS412/DatasByFolder/4\",\n",
        "          x_col=\"Id\",\n",
        "          y_col=\"Category\",\n",
        "          target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "          batch_size=batch_size,\n",
        "          # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "          class_mode='categorical',\n",
        "          save_to_dir=saveDir)\n",
        "  for i in range(1):\n",
        "    train_generator.next()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TseU2-RqHScp",
        "colab_type": "text"
      },
      "source": [
        "# Gather Data From Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb8JVlR-CVhv",
        "colab_type": "code",
        "outputId": "a6183f05-9c38-4785-a64c-ac53e734864c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "traincsv = pd.read_csv(\"/content/drive/My Drive/CS412/Train.csv\")\n",
        "traincsv[\"Id\"] += \".jpg\"\n",
        "#valData4 = traincsv.groupby(\"Category\").get_group(4).reset_index()\n",
        "#traincsv = traincsv[traincsv.Category != 4].copy()\n",
        "#for root, dirs, files in os.walk(\"/content/drive/My Drive/CS412/ImageAugmention/4\"):\n",
        "#  traincsv = traincsv.append(pd.DataFrame({'Id': files,'Category': [4] * len(files)}), ignore_index = True)\n",
        "\n",
        "for index in range(0, len(traincsv)):\n",
        "  if(traincsv[\"Category\"][index] != 4):\n",
        "    traincsv[\"Id\"][index] = \"DatasByFolder/\" + str(traincsv[\"Category\"][index]) + \"/\" + traincsv[\"Id\"][index]\n",
        "\n",
        "#for index in range(0, len(valData4)):\n",
        "#  valData4[\"Id\"][index] = \"DatasByFolder/\" + str(valData4[\"Category\"][index]) + \"/\" + valData4[\"Id\"][index]\n",
        "\n",
        "traincsv = traincsv.astype({\"Id\": str, \"Category\": str})\n",
        "#valData4 = valData4.astype({\"Id\": str, \"Category\": str})\n",
        "traincsv.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DatasByFolder/2/Image_1.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DatasByFolder/2/Image_2.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DatasByFolder/5/Image_3.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DatasByFolder/2/Image_4.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DatasByFolder/1/Image_5.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Id Category\n",
              "0  DatasByFolder/2/Image_1.jpg        2\n",
              "1  DatasByFolder/2/Image_2.jpg        2\n",
              "2  DatasByFolder/5/Image_3.jpg        5\n",
              "3  DatasByFolder/2/Image_4.jpg        2\n",
              "4  DatasByFolder/1/Image_5.jpg        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkPRsVartlwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trainData1, valData1 = train_test_split(traincsv.groupby(\"Category\").get_group(\"1\"), test_size=0.2)\n",
        "trainData2, valData2 = train_test_split(traincsv.groupby(\"Category\").get_group(\"2\"), test_size=0.2)\n",
        "trainData3, valData3 = train_test_split(traincsv.groupby(\"Category\").get_group(\"3\"), test_size=0.2)\n",
        "trainData4, valData4 = train_test_split(traincsv.groupby(\"Category\").get_group(\"4\"), test_size=0.2)\n",
        "trainData5, valData5 = train_test_split(traincsv.groupby(\"Category\").get_group(\"5\"), test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEe8XwjBKs9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData = pd.concat([trainData4, trainData1, trainData2.sample(2200), trainData3, trainData4, trainData5])\n",
        "trainData = trainData.sample(frac=1).reset_index(drop=True)\n",
        "valData = pd.concat([valData1, valData2, valData3, valData4, valData5])\n",
        "valData = valData.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvDURr8bO2Fn",
        "colab_type": "text"
      },
      "source": [
        "#Create from dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZkECr3_SKG0",
        "colab_type": "text"
      },
      "source": [
        "We used 224x224 for some of the models as picture size since it game better results in our models. We created a fixed number of augmenatation and saved them to create more augmented images. Above codes does file seperation and this save method on google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJRtO2HJFcTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        "  fill_mode='nearest') # set validation split\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "def dataGen(_trainData, _valData, _batchSize = 32, _class_mode=\"categorical\"):\n",
        "  # Flow training images in batches of 128 using train_datagen generator\n",
        "  _train_generator = train_datagen.flow_from_dataframe(\n",
        "          _trainData,  # This is the source directory for training images\n",
        "          directory=\"/content/drive/My Drive/CS412/\",\n",
        "          x_col=\"Id\",\n",
        "          y_col=\"Category\",\n",
        "          target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "          batch_size=_batchSize,\n",
        "          # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "          class_mode=_class_mode)\n",
        "\n",
        "  # Flow training images in batches of 128 using train_datagen generator\n",
        "  _validation_generator = validation_datagen.flow_from_dataframe(\n",
        "          _valData,  # This is the source directory for training images\n",
        "          directory=\"/content/drive/My Drive/CS412/\",\n",
        "          x_col=\"Id\",\n",
        "          y_col=\"Category\",\n",
        "          target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "          batch_size=_batchSize,\n",
        "          # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "          class_mode=_class_mode)\n",
        "\n",
        "  return _train_generator, _validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ZPJjbiO5J9",
        "colab_type": "text"
      },
      "source": [
        "#Create from folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaeoMKhMe2Xp",
        "colab_type": "code",
        "outputId": "1329669c-034f-498c-c3f8-fbdaef2b3d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 32\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "  rotation_range=40,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest') # set validation split\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/CS412/DatasByFolder',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "        batch_size=batch_size,\n",
        "        # Specify the classes explicitly\n",
        "        classes = [\"1\", \"2\", \"3\", \"4\", \"5\"],\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/CS412/ValidationDatas',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "        batch_size=batch_size,\n",
        "        # Specify the classes explicitly\n",
        "        classes = [\"1\", \"2\", \"3\", \"4\", \"5\"],\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 5 classes.\n",
            "Found 0 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk1Y_uL8Ma0u",
        "colab_type": "text"
      },
      "source": [
        "#Gather Test Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDrzRL2Pnxwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcsv = pd.read_csv(\"/content/drive/My Drive/CS412/Test.csv\")\n",
        "testcsv.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mylV6kMO6DYD",
        "colab_type": "code",
        "outputId": "42a0f458-08f9-45de-f619-752cad6b4ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 128\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# All images will be rescaled by 1./255\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/CS412/TestData',  # This is the source directory for training images\n",
        "        target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "        batch_size=50,\n",
        "        # Specify the classes explicitly\n",
        "        classes = [\"1\"],\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode=None,\n",
        "        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VGHl2j4HsjC",
        "colab_type": "text"
      },
      "source": [
        "#Inception ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZlK8lzNSWLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "%load_ext tensorboard\n",
        "root_logdir = os.path.join('/content/drive/My Drive/CS412', \"final_logs\")\n",
        "%tensorboard --logdir \"/content/drive/My Drive/CS412/final_logs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zANJRRAEYID-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNetModel_base = tf.keras.applications.InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "resNetModel_base.trainable = False\n",
        "\n",
        "resNetModel_base.trainable = True\n",
        "'''set_trainable = False\n",
        "for i in range(len(resNetModel_base.layers)):\n",
        "  if resNetModel_base.layers[i].name.find(\"block8\") != -1:\n",
        "    set_trainable = True\n",
        "  \n",
        "  resNetModel_base.layers[i].trainable = set_trainable'''\n",
        "\n",
        "resNetModel = tf.keras.models.Sequential([\n",
        "                                          resNetModel_base,\n",
        "                                          tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                          tf.keras.layers.Flatten(),\n",
        "                                          tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2()),\n",
        "                                          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                                          tf.keras.layers.Dropout(0.7),\n",
        "                                          tf.keras.layers.Dense(5, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2())\n",
        "])\n",
        "\n",
        "resNetModel.compile(loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.SGD(0.0008, 0.9),\n",
        "    metrics=[metrics.F1Score(5), \"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "393MO3HRjvsS",
        "colab_type": "code",
        "outputId": "eabf18d1-016e-49f6-db47-907ca7f92f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resNetModel.load_weights(\"/content/drive/My Drive/CS412/Checkpoints/cpresnet3.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf115b4ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0rNrHi7mbyG",
        "colab_type": "code",
        "outputId": "278f36a1-e865-44b5-a5b5-3dd8f4450d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "from os import walk\n",
        "from datetime import datetime\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\"\n",
        "checkpoint_path2 = \"/content/drive/My Drive/CS412/Checkpoints/cpdense35acc.ckpt\"\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "cp_callbackAcc = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path2,\n",
        "                                                    monitor=\"val_acc\",\n",
        "                                                    mode=\"max\",\n",
        "                                                    save_weights_only=True,\n",
        "                                                    save_best_only=True)\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_loss', min_delta=0.0001, mode=\"auto\",\n",
        "  patience=5, verbose=1)\n",
        "\n",
        "logdir = os.path.join(\"/content/drive/My Drive/CS412/final_logs\", \"Dense\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_cb= tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "batch_size = 32\n",
        "testSplit = 0.2\n",
        "cat1, val1 = train_test_split(traincsv.groupby(\"Category\").get_group(\"1\").sample(2135), test_size=testSplit)\n",
        "cat2, val2 = train_test_split(traincsv.groupby(\"Category\").get_group(\"2\").sample(2135), test_size=testSplit)\n",
        "cat3, val3 = train_test_split(traincsv.groupby(\"Category\").get_group(\"3\"), test_size=testSplit)\n",
        "cat4, val4 = train_test_split(traincsv.groupby(\"Category\").get_group(\"4\"), test_size=testSplit)\n",
        "cat5, val5 = train_test_split(traincsv.groupby(\"Category\").get_group(\"5\"), test_size=testSplit)\n",
        "#cat4 = np.array_split(valData4.sample(frac=1), fold_no)\n",
        "\n",
        "trainData4 = pd.DataFrame({\"Id\": [\"\"], \"Category\": [\"\"]})\n",
        "for _, row in cat4.iterrows():\n",
        "  if(len(row[\"Id\"]) < 4):\n",
        "    continue \n",
        "  f = []\n",
        "  for (dirpath, dirnames, filenames) in walk('/content/drive/My Drive/CS412/ImageAugmention/4/' + str(row[\"Id\"][:len(row[\"Id\"]) - 4])):\n",
        "    trainData4 = trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"4\"]}))\n",
        "    trainData4 = trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"4\"]}))\n",
        "    for filename in filenames:\n",
        "      trainData4 = trainData4.append(pd.DataFrame({\"Id\": [\"ImageAugmention/4/\" + str(row[\"Id\"][:len(row[\"Id\"]) - 4]) + \"/\" + filename], \"Category\": [\"4\"]}))\n",
        "    trainData4 = trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"4\"]}))\n",
        "trainData4.reset_index(inplace=True, drop=True)\n",
        "\n",
        "val4.reset_index(inplace=True, drop=True)\n",
        "for index in range(0, len(val4)):\n",
        "  val4[\"Id\"][index] = \"DatasByFolder/4/\" + val4[\"Id\"][index]\n",
        "\n",
        "histories = []\n",
        "\n",
        "trainData = pd.concat([cat1, cat2, cat3, trainData4, cat5])\n",
        "trainData = trainData.sample(frac=1).reset_index(drop=True)\n",
        "valData = pd.concat([val1, val2, val3, val4, val5])\n",
        "valData = valData.sample(frac=1).reset_index(drop=True)\n",
        "train_generator, validation_generator = dataGen(trainData, valData)\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                np.unique(train_generator.labels),\n",
        "                                                train_generator.labels)\n",
        "\n",
        "_weights = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], 3: class_weights[3], 4: class_weights[4]}\n",
        "print(_weights)\n",
        "n_epochs = 10\n",
        "history = denseNetModel.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=int(train_generator.n / train_generator.batch_size),  \n",
        "        epochs=n_epochs,\n",
        "        class_weight=_weights,\n",
        "        verbose=1,\n",
        "        callbacks=[cp_callback, cp_callbackAcc, earlystop_callback])\n",
        "histories = np.append(histories, history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 1 invalid image filename(s) in x_col=\"Id\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 7765 validated image filenames belonging to 5 classes.\n",
            "Found 1517 validated image filenames belonging to 5 classes.\n",
            "{0: 0.9092505854800936, 1: 0.9092505854800936, 2: 1.2199528672427338, 3: 0.7590420332355816, 4: 1.507766990291262}\n",
            "Epoch 1/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 1.4664 - f1_score: 0.4809 - acc: 0.4964\n",
            "Epoch 00001: val_loss improved from inf to 1.05493, saving model to /content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\n",
            "242/242 [==============================] - 317s 1s/step - loss: 1.4664 - f1_score: 0.4809 - acc: 0.4964 - val_loss: 1.0549 - val_f1_score: 0.5459 - val_acc: 0.6396\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 1.0548 - f1_score: 0.6198 - acc: 0.6347\n",
            "Epoch 00002: val_loss improved from 1.05493 to 0.95256, saving model to /content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\n",
            "242/242 [==============================] - 238s 985ms/step - loss: 1.0548 - f1_score: 0.6198 - acc: 0.6347 - val_loss: 0.9526 - val_f1_score: 0.5864 - val_acc: 0.6343\n",
            "Epoch 3/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.8999 - f1_score: 0.6726 - acc: 0.6851\n",
            "Epoch 00003: val_loss improved from 0.95256 to 0.90699, saving model to /content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\n",
            "242/242 [==============================] - 238s 982ms/step - loss: 0.8999 - f1_score: 0.6726 - acc: 0.6851 - val_loss: 0.9070 - val_f1_score: 0.6407 - val_acc: 0.6815\n",
            "Epoch 4/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.8122 - f1_score: 0.7048 - acc: 0.7173\n",
            "Epoch 00004: val_loss improved from 0.90699 to 0.87981, saving model to /content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\n",
            "242/242 [==============================] - 239s 989ms/step - loss: 0.8122 - f1_score: 0.7048 - acc: 0.7173 - val_loss: 0.8798 - val_f1_score: 0.6277 - val_acc: 0.6941\n",
            "Epoch 5/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.7370 - f1_score: 0.7392 - acc: 0.7508\n",
            "Epoch 00005: val_loss did not improve from 0.87981\n",
            "242/242 [==============================] - 236s 976ms/step - loss: 0.7370 - f1_score: 0.7392 - acc: 0.7508 - val_loss: 0.9332 - val_f1_score: 0.6327 - val_acc: 0.6669\n",
            "Epoch 6/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.6622 - f1_score: 0.7676 - acc: 0.7787\n",
            "Epoch 00006: val_loss improved from 0.87981 to 0.84235, saving model to /content/drive/My Drive/CS412/Checkpoints/cpdense35.ckpt\n",
            "242/242 [==============================] - 238s 984ms/step - loss: 0.6622 - f1_score: 0.7676 - acc: 0.7787 - val_loss: 0.8423 - val_f1_score: 0.6644 - val_acc: 0.7061\n",
            "Epoch 7/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.5920 - f1_score: 0.7982 - acc: 0.8082\n",
            "Epoch 00007: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 236s 975ms/step - loss: 0.5920 - f1_score: 0.7982 - acc: 0.8082 - val_loss: 0.9463 - val_f1_score: 0.6150 - val_acc: 0.6755\n",
            "Epoch 8/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.5452 - f1_score: 0.8161 - acc: 0.8257\n",
            "Epoch 00008: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 239s 990ms/step - loss: 0.5452 - f1_score: 0.8161 - acc: 0.8257 - val_loss: 0.8840 - val_f1_score: 0.6527 - val_acc: 0.7055\n",
            "Epoch 9/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4964 - f1_score: 0.8323 - acc: 0.8396\n",
            "Epoch 00009: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 242s 1s/step - loss: 0.4964 - f1_score: 0.8323 - acc: 0.8396 - val_loss: 0.8502 - val_f1_score: 0.6529 - val_acc: 0.7281\n",
            "Epoch 10/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4439 - f1_score: 0.8484 - acc: 0.8550\n",
            "Epoch 00010: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 239s 989ms/step - loss: 0.4439 - f1_score: 0.8484 - acc: 0.8550 - val_loss: 0.8912 - val_f1_score: 0.6833 - val_acc: 0.7274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0tQEKDvIrV4",
        "colab_type": "code",
        "outputId": "c306c832-691e-43b1-8b06-b68115addc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "n_epochs = 10\n",
        "history = denseNetModel.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=int(train_generator.n / train_generator.batch_size),  \n",
        "        epochs=n_epochs,\n",
        "        class_weight=_weights,\n",
        "        verbose=1,\n",
        "        callbacks=[cp_callback, cp_callbackAcc, earlystop_callback])\n",
        "histories = np.append(histories, history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.5875 - f1_score: 0.7969 - acc: 0.8060\n",
            "Epoch 00001: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 238s 982ms/step - loss: 0.5875 - f1_score: 0.7969 - acc: 0.8060 - val_loss: 0.9705 - val_f1_score: 0.6274 - val_acc: 0.6961\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.5378 - f1_score: 0.8154 - acc: 0.8234\n",
            "Epoch 00002: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 237s 978ms/step - loss: 0.5378 - f1_score: 0.8154 - acc: 0.8234 - val_loss: 0.8605 - val_f1_score: 0.6595 - val_acc: 0.7241\n",
            "Epoch 3/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4822 - f1_score: 0.8356 - acc: 0.8425\n",
            "Epoch 00003: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 239s 988ms/step - loss: 0.4822 - f1_score: 0.8356 - acc: 0.8425 - val_loss: 0.9066 - val_f1_score: 0.6758 - val_acc: 0.7207\n",
            "Epoch 4/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4555 - f1_score: 0.8473 - acc: 0.8539\n",
            "Epoch 00004: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 241s 996ms/step - loss: 0.4555 - f1_score: 0.8473 - acc: 0.8539 - val_loss: 0.9948 - val_f1_score: 0.6525 - val_acc: 0.7068\n",
            "Epoch 5/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3979 - f1_score: 0.8657 - acc: 0.8721\n",
            "Epoch 00005: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 244s 1s/step - loss: 0.3979 - f1_score: 0.8657 - acc: 0.8721 - val_loss: 0.9102 - val_f1_score: 0.6852 - val_acc: 0.7214\n",
            "Epoch 6/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3847 - f1_score: 0.8710 - acc: 0.8759\n",
            "Epoch 00006: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 242s 999ms/step - loss: 0.3847 - f1_score: 0.8710 - acc: 0.8759 - val_loss: 0.8952 - val_f1_score: 0.6872 - val_acc: 0.7241\n",
            "Epoch 7/10\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3548 - f1_score: 0.8861 - acc: 0.8903\n",
            "Epoch 00007: val_loss did not improve from 0.84235\n",
            "242/242 [==============================] - 239s 988ms/step - loss: 0.3548 - f1_score: 0.8861 - acc: 0.8903 - val_loss: 0.9723 - val_f1_score: 0.6889 - val_acc: 0.7274\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFdC8W6NSJUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denseNetModel.save(\"/content/drive/My Drive/CS412/Models/densenet6889_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGRMjl4-Hh4x",
        "colab_type": "text"
      },
      "source": [
        "Classification Matrix and Reports on Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAblrC1n2kcT",
        "colab_type": "code",
        "outputId": "76f6521a-2d96-45a7-bf04-3b33122f9b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "classification_generator = validation_datagen.flow_from_dataframe(\n",
        "          valData,  # This is the source directory for training images\n",
        "          directory=\"/content/drive/My Drive/CS412/\",\n",
        "          x_col=\"Id\",\n",
        "          y_col=\"Category\",\n",
        "          target_size=(224, 224),  # All images will be resized to 200 x 200\n",
        "          batch_size=32,\n",
        "          shuffle = False,\n",
        "          # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "          class_mode='categorical')\n",
        "\n",
        "#denseNetModel.load_weights(checkpoint_path)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = denseNetModel.predict(classification_generator, classification_generator.samples // 32+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(classification_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['1', '2', '3', '4', '5']\n",
        "print(classification_report(classification_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1517 validated image filenames belonging to 5 classes.\n",
            "Confusion Matrix\n",
            "[[266  67  34  10  50]\n",
            " [ 47 316  18   3  43]\n",
            " [  4  10 263  10  32]\n",
            " [  7   0  22  36  21]\n",
            " [ 25  20  11   9 193]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.76      0.62      0.69       427\n",
            "           2       0.77      0.74      0.75       427\n",
            "           3       0.76      0.82      0.79       319\n",
            "           4       0.53      0.42      0.47        86\n",
            "           5       0.57      0.75      0.65       258\n",
            "\n",
            "    accuracy                           0.71      1517\n",
            "   macro avg       0.68      0.67      0.67      1517\n",
            "weighted avg       0.72      0.71      0.71      1517\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTy-fh8gHnSr",
        "colab_type": "text"
      },
      "source": [
        "Performance of each class can be seen in this graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xzu81-vgzu1",
        "colab_type": "code",
        "outputId": "21dfc2ff-a8f3-4d94-b167-69addf49f39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "# Plot training & validation loss values\n",
        "bycat = np.transpose(histories[0].history[\"val_f1_score\"])\n",
        "pyplot.plot(bycat[0])\n",
        "pyplot.plot(bycat[1])\n",
        "pyplot.plot(bycat[2])\n",
        "pyplot.plot(bycat[3])\n",
        "pyplot.plot(bycat[4])\n",
        "pyplot.ylim(0,1)\n",
        "pyplot.title('Model F1 Score')\n",
        "pyplot.ylabel('F1 Score')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Cat1', 'Cat2', \"Cat3\", \"Cat4\", \"Cat5\"], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8xm_cl4HxvJ",
        "colab_type": "text"
      },
      "source": [
        "#DenseNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKQH0r2d5Gpl",
        "colab_type": "code",
        "outputId": "1a784bfb-1234-493b-97eb-99e2b1d89dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "denseNetModel_base = tf.keras.applications.DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(256, 256, 3))\n",
        "denseNetModel_base.trainable = False\n",
        "\n",
        "denseNetModel_base.trainable = True\n",
        "set_trainable = False\n",
        "for i in range(len(denseNetModel_base.layers)):\n",
        "  if denseNetModel_base.layers[i].name.find(\"conv4\") != -1:\n",
        "    set_trainable = True\n",
        "  \n",
        "  denseNetModel_base.layers[i].trainable = set_trainable\n",
        "\n",
        "denseNetModel = tf.keras.models.Sequential([\n",
        "                                            denseNetModel_base,\n",
        "                                            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                            tf.keras.layers.Flatten(),\n",
        "                                            tf.keras.layers.Dropout(0.7),\n",
        "                                            #tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "                                            tf.keras.layers.Dense(5, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2())\n",
        "])\n",
        "\n",
        "denseNetModel.compile(loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.SGD(0.0006, 0.9),\n",
        "    metrics=[metrics.F1Score(5), \"acc\"])\n",
        "\n",
        "total_sample=train_generator.n\n",
        "\n",
        "cat1, val1 = train_test_split(traincsv.groupby(\"Category\").get_group(\"1\").sample(frac=1), test_size=0.2)\n",
        "cat2, val2 = train_test_split(traincsv.groupby(\"Category\").get_group(\"2\").sample(3200).sample(frac=1), test_size=0.2)\n",
        "cat3, val3 = train_test_split(traincsv.groupby(\"Category\").get_group(\"3\").sample(frac=1), test_size=0.2)\n",
        "cat4, val4 = train_test_split(traincsv.groupby(\"Category\").get_group(\"4\").sample(frac=1), test_size=0.2)\n",
        "cat5, val5 = train_test_split(traincsv.groupby(\"Category\").get_group(\"5\").sample(frac=1), test_size=0.2)\n",
        "\n",
        "cat4.reset_index(inplace=True, drop=True)\n",
        "val4.reset_index(inplace=True, drop=True)\n",
        "\n",
        "for index in range(0, len(cat4)):\n",
        "  cat4[\"Id\"][index] = \"DatasByFolder/4/\" + cat4[\"Id\"][index]\n",
        "  \n",
        "for index in range(0, len(val4)):\n",
        "  val4[\"Id\"][index] = \"DatasByFolder/4/\" + val4[\"Id\"][index]\n",
        "\n",
        "histories = []\n",
        "\n",
        "trainData = pd.concat([cat1, cat2, cat3, cat4, cat5])\n",
        "trainData = trainData.sample(frac=1).reset_index(drop=True)\n",
        "valData = pd.concat([val1, val2, val3, val4, val5])\n",
        "valData = valData.sample(frac=1).reset_index(drop=True)\n",
        "train_generator, validation_generator = dataGen(trainData, valData)\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                np.unique(train_generator.classes),\n",
        "                                                train_generator.classes)\n",
        "_weights = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], 3: class_weights[3], 4: class_weights[4]}\n",
        "\n",
        "n_epochs = 30\n",
        "history = denseNetModel.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=30,  \n",
        "        epochs=n_epochs,\n",
        "        class_weight=_weights,\n",
        "        verbose=1)\n",
        "histories = np.append(histories, history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6967 validated image filenames belonging to 5 classes.\n",
            "Found 1744 validated image filenames belonging to 5 classes.\n",
            "Epoch 1/30\n",
            "30/30 [==============================] - 62s 2s/step - loss: 2.1630 - f1_score: 0.2194 - acc: 0.2450 - val_loss: 1.5254 - val_f1_score: 0.2888 - val_acc: 0.4062\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 55s 2s/step - loss: 1.8144 - f1_score: 0.3399 - acc: 0.4052 - val_loss: 1.3726 - val_f1_score: 0.3332 - val_acc: 0.4519\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 47s 2s/step - loss: 1.5335 - f1_score: 0.3899 - acc: 0.4187 - val_loss: 1.2579 - val_f1_score: 0.3879 - val_acc: 0.4976\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 40s 1s/step - loss: 1.5052 - f1_score: 0.4334 - acc: 0.4771 - val_loss: 1.2049 - val_f1_score: 0.4612 - val_acc: 0.5649\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 41s 1s/step - loss: 1.3876 - f1_score: 0.4331 - acc: 0.4875 - val_loss: 1.0860 - val_f1_score: 0.5792 - val_acc: 0.6466\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 40s 1s/step - loss: 1.3280 - f1_score: 0.4892 - acc: 0.5323 - val_loss: 1.0176 - val_f1_score: 0.5353 - val_acc: 0.6034\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 38s 1s/step - loss: 1.3465 - f1_score: 0.4729 - acc: 0.5219 - val_loss: 1.0049 - val_f1_score: 0.5432 - val_acc: 0.6178\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 33s 1s/step - loss: 1.2339 - f1_score: 0.5182 - acc: 0.5552 - val_loss: 0.9699 - val_f1_score: 0.5924 - val_acc: 0.6538\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 36s 1s/step - loss: 1.2201 - f1_score: 0.4996 - acc: 0.5500 - val_loss: 1.0199 - val_f1_score: 0.5922 - val_acc: 0.6298\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 35s 1s/step - loss: 1.2343 - f1_score: 0.5201 - acc: 0.5594 - val_loss: 0.9208 - val_f1_score: 0.6241 - val_acc: 0.6755\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 35s 1s/step - loss: 1.1504 - f1_score: 0.5244 - acc: 0.5719 - val_loss: 0.9309 - val_f1_score: 0.5723 - val_acc: 0.6178\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 31s 1s/step - loss: 1.1861 - f1_score: 0.5296 - acc: 0.5668 - val_loss: 0.9612 - val_f1_score: 0.5961 - val_acc: 0.6178\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 30s 996ms/step - loss: 1.0790 - f1_score: 0.5431 - acc: 0.6062 - val_loss: 1.0414 - val_f1_score: 0.5477 - val_acc: 0.6082\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 32s 1s/step - loss: 1.0139 - f1_score: 0.5800 - acc: 0.6281 - val_loss: 0.9060 - val_f1_score: 0.6099 - val_acc: 0.6635\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 31s 1s/step - loss: 1.1245 - f1_score: 0.5676 - acc: 0.6052 - val_loss: 0.9410 - val_f1_score: 0.5978 - val_acc: 0.6394\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 30s 994ms/step - loss: 0.9461 - f1_score: 0.6172 - acc: 0.6583 - val_loss: 0.8893 - val_f1_score: 0.6336 - val_acc: 0.6659\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 31s 1s/step - loss: 1.0086 - f1_score: 0.6071 - acc: 0.6510 - val_loss: 0.9601 - val_f1_score: 0.6008 - val_acc: 0.6538\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 31s 1s/step - loss: 1.0295 - f1_score: 0.5842 - acc: 0.6229 - val_loss: 0.9714 - val_f1_score: 0.5864 - val_acc: 0.6322\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 29s 968ms/step - loss: 1.0359 - f1_score: 0.5820 - acc: 0.6141 - val_loss: 0.9118 - val_f1_score: 0.5613 - val_acc: 0.6394\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 29s 977ms/step - loss: 0.9639 - f1_score: 0.6035 - acc: 0.6438 - val_loss: 0.8961 - val_f1_score: 0.6076 - val_acc: 0.6514\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 31s 1s/step - loss: 0.9476 - f1_score: 0.6280 - acc: 0.6687 - val_loss: 0.9422 - val_f1_score: 0.6240 - val_acc: 0.6562\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 29s 963ms/step - loss: 0.9289 - f1_score: 0.6169 - acc: 0.6573 - val_loss: 0.9812 - val_f1_score: 0.6076 - val_acc: 0.6394\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 29s 966ms/step - loss: 1.0057 - f1_score: 0.6091 - acc: 0.6498 - val_loss: 1.0910 - val_f1_score: 0.5232 - val_acc: 0.5601\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 29s 979ms/step - loss: 0.9889 - f1_score: 0.5895 - acc: 0.6344 - val_loss: 0.8825 - val_f1_score: 0.6089 - val_acc: 0.6635\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 29s 979ms/step - loss: 0.9291 - f1_score: 0.6415 - acc: 0.6729 - val_loss: 0.9280 - val_f1_score: 0.5941 - val_acc: 0.6538\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 29s 952ms/step - loss: 0.9212 - f1_score: 0.6317 - acc: 0.6698 - val_loss: 0.9849 - val_f1_score: 0.6155 - val_acc: 0.6442\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 29s 952ms/step - loss: 0.8519 - f1_score: 0.6360 - acc: 0.6792 - val_loss: 0.8954 - val_f1_score: 0.6172 - val_acc: 0.6538\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 29s 978ms/step - loss: 0.9459 - f1_score: 0.6318 - acc: 0.6667 - val_loss: 0.8401 - val_f1_score: 0.6421 - val_acc: 0.6755\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 29s 962ms/step - loss: 0.8606 - f1_score: 0.6366 - acc: 0.6948 - val_loss: 0.8438 - val_f1_score: 0.5999 - val_acc: 0.6923\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 29s 970ms/step - loss: 0.8177 - f1_score: 0.6589 - acc: 0.7021 - val_loss: 0.8772 - val_f1_score: 0.6197 - val_acc: 0.6779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m0FZm5lg-u-",
        "colab_type": "code",
        "outputId": "87b825b6-4360-4068-a393-345b73ba9185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "denseNetModel.load_weights(\"/content/drive/My Drive/CS412/Models/cpdense.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf10b22f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYKHAeYAfL33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denseNetModel.save(\"/content/drive/My Drive/CS412/Models/densenet_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E55UFuj_9dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "logdir = os.path.join(\"final_logs\", denseNetModel.name + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_cb= tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7DlvbYxOe6u",
        "colab_type": "code",
        "outputId": "53e0d758-8652-4335-abc4-e428a5fe1baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred = np.argmax(denseNetModel.predict(test_generator, verbose=1, steps=5000/50), axis=-1)\n",
        "filenames = test_generator.filenames\n",
        "for i in range(len(filenames)):\n",
        "  filenames[i] = filenames[i][2:len(filenames[i])-4]\n",
        "res = pd.DataFrame({'Id': filenames,'Category': pred + 1})\n",
        "res.set_index(\"Id\", inplace=True)\n",
        "res.to_csv(\"/content/drive/My Drive/CS412/Pred2.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  3/100 [..............................] - ETA: 18:58"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "its4Os3xIAmj",
        "colab_type": "text"
      },
      "source": [
        "#Xception Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-TzFiMvH156",
        "colab_type": "text"
      },
      "source": [
        "Current xception model guesses binary between 4 or not. The only main difference is last dense layer has 5 in main model. We had no time to revert it and run it again since we used two models. But we can provide saved model as md5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbR4ftbB7DrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xceptionModel_base = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "xceptionModel_base.trainable = False\n",
        "\n",
        "xceptionModel_base.trainable = True\n",
        "set_trainable = False\n",
        "for i in range(len(xceptionModel_base.layers)):\n",
        "  if xceptionModel_base.layers[i].name.find(\"block4_conv1\") != -1:\n",
        "    set_trainable = True\n",
        "  elif xceptionModel_base.layers[i].name.find(\"block5_conv1\") != -1:\n",
        "    set_trainable = True\n",
        "  \n",
        "  xceptionModel_base.layers[i].trainable = set_trainable\n",
        "\n",
        "xceptionModel = tf.keras.models.Sequential([\n",
        "                                            xceptionModel_base,\n",
        "                                            # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    # 5 output neurons for 5 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "xceptionModel.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
        "    metrics=[metrics.F1Score(2), \"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxeYUcP8m2Dp",
        "colab_type": "code",
        "outputId": "d9a345a5-4468-43c9-9c4d-1d4a3bfb49d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from os import walk\n",
        "from datetime import datetime\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/CS412/Checkpoints/xception4.ckpt\"\n",
        "checkpoint_path2 = \"/content/drive/My Drive/CS412/Checkpoints/xception4acc.ckpt\"\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "cp_callbackAcc = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path2,\n",
        "                                                    monitor=\"val_acc\",\n",
        "                                                    mode=\"max\",\n",
        "                                                    save_weights_only=True,\n",
        "                                                    save_best_only=True)\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_loss', min_delta=0.0001, mode=\"auto\",\n",
        "  patience=5, verbose=1)\n",
        "\n",
        "logdir = os.path.join(\"/content/drive/My Drive/CS412/final_logs\", \"Dense\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_cb= tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "batch_size = 32\n",
        "testSplit = 0.2\n",
        "_cat1, _val1 = train_test_split(traincsv.groupby(\"Category\").get_group(\"1\").sample(900), test_size=testSplit)\n",
        "_cat2, _val2 = train_test_split(traincsv.groupby(\"Category\").get_group(\"2\").sample(900), test_size=testSplit)\n",
        "_cat3, _val3 = train_test_split(traincsv.groupby(\"Category\").get_group(\"3\").sample(900), test_size=testSplit)\n",
        "_cat4, _val4 = train_test_split(traincsv.groupby(\"Category\").get_group(\"4\"), test_size=testSplit)\n",
        "_cat5, _val5 = train_test_split(traincsv.groupby(\"Category\").get_group(\"5\").sample(900), test_size=testSplit)\n",
        "#cat4 = np.array_split(valData4.sample(frac=1), fold_no)\n",
        "\n",
        "_val4[\"Category\"] = \"0\"\n",
        "\n",
        "_cat1[\"Category\"] = \"1\"\n",
        "_cat2[\"Category\"] = \"1\"\n",
        "_cat3[\"Category\"] = \"1\"\n",
        "_cat5[\"Category\"] = \"1\"\n",
        "_val1[\"Category\"] = \"1\"\n",
        "_val1 = _val1.sample(50)\n",
        "_val2[\"Category\"] = \"1\"\n",
        "_val2 = _val2.sample(50)\n",
        "_val3[\"Category\"] = \"1\"\n",
        "_val3 = _val3.sample(50)\n",
        "_val5[\"Category\"] = \"1\"\n",
        "_val5 = _val5.sample(50)\n",
        "\n",
        "\n",
        "_trainData4 = pd.DataFrame({\"Id\": [\"\"], \"Category\": [\"\"]})\n",
        "for _, row in _cat4.iterrows():\n",
        "  if(len(row[\"Id\"]) < 4):\n",
        "    continue \n",
        "  f = []\n",
        "  for (dirpath, dirnames, filenames) in walk('/content/drive/My Drive/CS412/ImageAugmention/4/' + str(row[\"Id\"][:len(row[\"Id\"]) - 4])):\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    for filename in filenames:\n",
        "      _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"ImageAugmention/4/\" + str(row[\"Id\"][:len(row[\"Id\"]) - 4]) + \"/\" + filename], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "    _trainData4 = _trainData4.append(pd.DataFrame({\"Id\": [\"DatasByFolder/4/\" + str(row[\"Id\"])], \"Category\": [\"0\"]}))\n",
        "_trainData4 = _trainData4[_trainData4.Category != \"\"]\n",
        "_trainData4.reset_index(inplace=True, drop=True)\n",
        "\n",
        "_val4.reset_index(inplace=True, drop=True)\n",
        "for index in range(0, len(_val4)):\n",
        "  _val4[\"Id\"][index] = \"DatasByFolder/4/\" + _val4[\"Id\"][index]\n",
        "_val4 = pd.concat([_val4, _val4, _val4,])\n",
        "_val4.reset_index(inplace=True, drop=True)\n",
        "\n",
        "histories = []\n",
        "\n",
        "_trainData = pd.concat([_cat1, _cat2, _cat3, _trainData4, _cat5])\n",
        "_trainData = _trainData.sample(frac=1).reset_index(drop=True)\n",
        "_valData = pd.concat([_val1, _val2, _val3, _val4, _val5])\n",
        "_valData = _valData.sample(frac=1).reset_index(drop=True)\n",
        "train_generator, validation_generator = dataGen(_trainData, _valData)\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                np.unique(train_generator.labels),\n",
        "                                                train_generator.labels)\n",
        "\n",
        "#_weights = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], 3: class_weights[3], 4: class_weights[4]}\n",
        "#print(_weights)\n",
        "n_epochs = 3\n",
        "history = xceptionModel.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=30,  \n",
        "        epochs=n_epochs,\n",
        "        verbose=1,\n",
        "        callbacks=[cp_callback, cp_callbackAcc, earlystop_callback])\n",
        "histories = np.append(histories, history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6290 validated image filenames belonging to 2 classes.\n",
            "Found 458 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.6678 - f1_score: 0.5812 - acc: 0.6010\n",
            "Epoch 00001: val_loss improved from inf to 0.64697, saving model to /content/drive/My Drive/CS412/Checkpoints/xception4.ckpt\n",
            "30/30 [==============================] - 43s 1s/step - loss: 0.6678 - f1_score: 0.5812 - acc: 0.6010 - val_loss: 0.6470 - val_f1_score: 0.6438 - val_acc: 0.6496\n",
            "Epoch 2/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5899 - f1_score: 0.7633 - acc: 0.7667\n",
            "Epoch 00002: val_loss improved from 0.64697 to 0.64307, saving model to /content/drive/My Drive/CS412/Checkpoints/xception4.ckpt\n",
            "30/30 [==============================] - 35s 1s/step - loss: 0.5899 - f1_score: 0.7633 - acc: 0.7667 - val_loss: 0.6431 - val_f1_score: 0.6248 - val_acc: 0.6339\n",
            "Epoch 3/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5711 - f1_score: 0.7689 - acc: 0.7780\n",
            "Epoch 00003: val_loss improved from 0.64307 to 0.56422, saving model to /content/drive/My Drive/CS412/Checkpoints/xception4.ckpt\n",
            "30/30 [==============================] - 35s 1s/step - loss: 0.5711 - f1_score: 0.7689 - acc: 0.7780 - val_loss: 0.5642 - val_f1_score: 0.7883 - val_acc: 0.7902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctq-PTjKz6Qd",
        "colab_type": "code",
        "outputId": "756f9f61-dc52-416d-de6a-54531ab857fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "n_epochs = 3\n",
        "history = xceptionModel.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=30,  \n",
        "        epochs=n_epochs,\n",
        "        verbose=1,\n",
        "        callbacks=[cp_callback, cp_callbackAcc, earlystop_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4943 - f1_score: 0.8018 - acc: 0.8062\n",
            "Epoch 00001: val_loss did not improve from 0.53227\n",
            "30/30 [==============================] - 29s 969ms/step - loss: 0.4943 - f1_score: 0.8018 - acc: 0.8062 - val_loss: 0.5337 - val_f1_score: 0.7807 - val_acc: 0.7812\n",
            "Epoch 2/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4900 - f1_score: 0.8093 - acc: 0.8135\n",
            "Epoch 00002: val_loss improved from 0.53227 to 0.50388, saving model to /content/drive/My Drive/CS412/Checkpoints/xception4.ckpt\n",
            "30/30 [==============================] - 30s 1s/step - loss: 0.4900 - f1_score: 0.8093 - acc: 0.8135 - val_loss: 0.5039 - val_f1_score: 0.7855 - val_acc: 0.7902\n",
            "Epoch 3/3\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4632 - f1_score: 0.8202 - acc: 0.8229\n",
            "Epoch 00003: val_loss did not improve from 0.50388\n",
            "30/30 [==============================] - 29s 976ms/step - loss: 0.4632 - f1_score: 0.8202 - acc: 0.8229 - val_loss: 0.6343 - val_f1_score: 0.6698 - val_acc: 0.6763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzkP5QYxIci6",
        "colab_type": "text"
      },
      "source": [
        "Classification of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV-_Jj7kV0Ps",
        "colab_type": "code",
        "outputId": "fbd3933d-1ce1-4fdc-8530-fddb9d84fe08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "classification_generator = validation_datagen.flow_from_dataframe(\n",
        "          _valData,  # This is the source directory for training images\n",
        "          directory=\"/content/drive/My Drive/CS412/\",\n",
        "          x_col=\"Id\",\n",
        "          y_col=\"Category\",\n",
        "          target_size=(256, 256),  # All images will be resized to 200 x 200\n",
        "          batch_size=32,\n",
        "          shuffle = False,\n",
        "          # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "          class_mode='categorical')\n",
        "\n",
        "#denseNetModel.load_weights(checkpoint_path)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = xceptionModel.predict(classification_generator, classification_generator.samples // 32+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(classification_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['0', '1']\n",
        "print(classification_report(classification_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 458 validated image filenames belonging to 2 classes.\n",
            "Confusion Matrix\n",
            "[[  0 258]\n",
            " [  0 200]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       258\n",
            "           1       0.44      1.00      0.61       200\n",
            "\n",
            "    accuracy                           0.44       458\n",
            "   macro avg       0.22      0.50      0.30       458\n",
            "weighted avg       0.19      0.44      0.27       458\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR5Om5B-PafD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xceptionModel.save(\"/content/drive/My Drive/CS412/Models/xception_model_test.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ7ryj4W25Dn",
        "colab_type": "code",
        "outputId": "9aa8aa1d-1b45-4ff2-8b49-45d876bf22ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "pred = np.argmax(dense.predict(test_generator, verbose=1, steps=5000/50), axis=-1)\n",
        "filenames = test_generator.filenames\n",
        "for i in range(len(filenames)):\n",
        "  filenames[i] = filenames[i][2:len(filenames[i])-4]\n",
        "res = pd.DataFrame({'Id': filenames,'Category': pred + 1})\n",
        "res.set_index(\"Id\", inplace=True)\n",
        "res.to_csv(\"/content/drive/My Drive/CS412/Pred2.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1f47fe1b02f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenseNetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6R_syo1IFBC",
        "colab_type": "text"
      },
      "source": [
        "#Results From K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vfa84t4IBPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = []\n",
        "loss = []\n",
        "f1 = []\n",
        "val_acc = []\n",
        "val_loss = []\n",
        "val_f1 = []\n",
        "for history in histories:\n",
        "  acc = np.append(acc, history.history[\"acc\"])\n",
        "  val_acc = np.append(val_acc, history.history[\"val_acc\"])\n",
        "  loss = np.append(loss, history.history[\"loss\"])\n",
        "  val_loss = np.append(val_loss, history.history[\"val_loss\"])\n",
        "  f1 = np.append(f1, history.history[\"f1_score\"])\n",
        "  val_f1 = np.append(val_f1, history.history[\"val_f1_score\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYwB1qcIIJee",
        "colab_type": "text"
      },
      "source": [
        "#Plot Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jG-cjrgI5RU",
        "colab_type": "text"
      },
      "source": [
        "This graphs show current binary classifier for 4 - or not. It is an old iteration and we could not realy worked it at further iterations. Due to dead relu problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5duuzE-V8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(f1)):\n",
        "  f1[i] = np.average(f1[i])\n",
        "  val_f1[i] = np.average(val_f1[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZKLKctS51Jz",
        "colab_type": "code",
        "outputId": "0f86c6ce-a9e2-428e-c87e-52d456bdcd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "pyplot.plot(acc)\n",
        "pyplot.plot(val_acc)\n",
        "pyplot.title('Model accuracy')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Train', 'Validation'], loc='upper left')\n",
        "pyplot.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "pyplot.plot(loss)\n",
        "pyplot.plot(val_loss)\n",
        "pyplot.title('Model loss')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Train', 'Validation'], loc='upper left')\n",
        "pyplot.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "pyplot.plot(f1)\n",
        "pyplot.plot(val_f1)\n",
        "pyplot.title('Model F1 Score')\n",
        "pyplot.ylabel('F1 Score')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Train', 'Validation'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nah4vJLFITm4",
        "colab_type": "text"
      },
      "source": [
        "#Handmade Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH3S2dWaJLsE",
        "colab_type": "text"
      },
      "source": [
        "This is first model of we used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF2sA1tZhbnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 128x 128 with 3 bytes color\n",
        "    # The first convolution\n",
        "    tf.keras.layers.Conv2D(filters=16, strides=(2,2), activation='relu', input_shape=(256, 256, 3), kernel_size=5),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (2,2), activation='relu', kernel_size=3),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(32, strides=2, activation='relu', kernel_size=4),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, strides=2, activation='relu', kernel_size=3),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    # 5 output neurons for 5 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[metrics.F1Score(5), \"acc\"])\n",
        "\n",
        "total_sample=train_generator.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hamnDrIAXHX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_generator.classes),\n",
        "                                                 train_generator.classes)\n",
        "_weights = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], 3: class_weights[3], 4: class_weights[4]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Y84yJ3ltap",
        "colab_type": "code",
        "outputId": "467820d1-969c-4aa8-c4e8-f872ee72aa03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.74963131, 0.60045434, 1.03817753, 3.87565982, 1.2831068 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ab_S-l5JQ42",
        "colab_type": "text"
      },
      "source": [
        "This is an old iteration which has very low results. At that point we felt the need of transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Py1VAmgZkK",
        "colab_type": "code",
        "outputId": "e76796ad-7f25-4654-c53c-31549450ed7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "n_epochs = 20\n",
        "history = model.fit(\n",
        "        train_generator, \n",
        "        validation_data = validation_generator, \n",
        "        validation_steps = validation_generator.samples // batch_size,\n",
        "        steps_per_epoch=int(total_sample/batch_size),  \n",
        "        epochs=n_epochs,\n",
        "        class_weight={0: 0.74963131, 1: 0.60045434, 2: 1.03817753, 3: 3.87565982, 4: 1.2831068},\n",
        "        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 757s 15s/step - loss: 1.5559 - f1_score: 0.1752 - acc: 0.2744 - val_loss: 1.3635 - val_f1_score: 0.1923 - val_acc: 0.3359\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 553s 11s/step - loss: 1.5065 - f1_score: 0.2136 - acc: 0.3019 - val_loss: 1.4178 - val_f1_score: 0.1884 - val_acc: 0.2812\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 432s 9s/step - loss: 1.4562 - f1_score: 0.2219 - acc: 0.2988 - val_loss: 1.3759 - val_f1_score: 0.2590 - val_acc: 0.4036\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 320s 6s/step - loss: 1.4415 - f1_score: 0.2880 - acc: 0.3806 - val_loss: 1.3651 - val_f1_score: 0.2342 - val_acc: 0.3255\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 247s 5s/step - loss: 1.3921 - f1_score: 0.2791 - acc: 0.3781 - val_loss: 1.2926 - val_f1_score: 0.2896 - val_acc: 0.4583\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 189s 4s/step - loss: 1.4680 - f1_score: 0.2429 - acc: 0.3088 - val_loss: 1.3506 - val_f1_score: 0.3100 - val_acc: 0.4193\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 144s 3s/step - loss: 1.4705 - f1_score: 0.3123 - acc: 0.4087 - val_loss: 1.3742 - val_f1_score: 0.2463 - val_acc: 0.3411\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 125s 3s/step - loss: 1.4090 - f1_score: 0.3143 - acc: 0.3894 - val_loss: 1.4799 - val_f1_score: 0.2834 - val_acc: 0.3359\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 98s 2s/step - loss: 1.3494 - f1_score: 0.3161 - acc: 0.4050 - val_loss: 1.3245 - val_f1_score: 0.2803 - val_acc: 0.3958\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 86s 2s/step - loss: 1.3775 - f1_score: 0.3557 - acc: 0.4406 - val_loss: 1.2850 - val_f1_score: 0.2975 - val_acc: 0.3906\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 75s 2s/step - loss: 1.3039 - f1_score: 0.3203 - acc: 0.4142 - val_loss: 1.2698 - val_f1_score: 0.3264 - val_acc: 0.4062\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 103s 2s/step - loss: 1.2630 - f1_score: 0.3669 - acc: 0.4712 - val_loss: 1.2574 - val_f1_score: 0.3550 - val_acc: 0.4167\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 62s 1s/step - loss: 1.3229 - f1_score: 0.3670 - acc: 0.4319 - val_loss: 1.2032 - val_f1_score: 0.3537 - val_acc: 0.4375\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 58s 1s/step - loss: 1.3206 - f1_score: 0.3603 - acc: 0.4338 - val_loss: 1.2922 - val_f1_score: 0.3462 - val_acc: 0.4089\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 55s 1s/step - loss: 1.2765 - f1_score: 0.3740 - acc: 0.4625 - val_loss: 1.2811 - val_f1_score: 0.3246 - val_acc: 0.4245\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 50s 1s/step - loss: 1.2518 - f1_score: 0.3821 - acc: 0.4769 - val_loss: 1.3308 - val_f1_score: 0.3345 - val_acc: 0.4193\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 50s 992ms/step - loss: 1.2494 - f1_score: 0.3658 - acc: 0.4594 - val_loss: 1.2145 - val_f1_score: 0.3369 - val_acc: 0.4167\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 47s 937ms/step - loss: 1.2440 - f1_score: 0.3749 - acc: 0.4462 - val_loss: 1.2441 - val_f1_score: 0.3946 - val_acc: 0.4661\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 47s 938ms/step - loss: 1.2298 - f1_score: 0.4150 - acc: 0.5069 - val_loss: 1.2041 - val_f1_score: 0.4203 - val_acc: 0.5078\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 48s 951ms/step - loss: 1.2636 - f1_score: 0.4002 - acc: 0.4700 - val_loss: 1.2622 - val_f1_score: 0.3531 - val_acc: 0.4479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO321EoiJfIj",
        "colab_type": "text"
      },
      "source": [
        "This code gives test scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkcccVSY8wKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.argmax(model.predict(test_generator, verbose=1, steps=5000/50), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKQbkdK5_emS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = test_generator.filenames\n",
        "for i in range(len(filenames)):\n",
        "  filenames[i] = filenames[i][2:len(filenames[i])-4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty8ZtU1SJy0Q",
        "colab_type": "code",
        "outputId": "70bb5970-2686-478e-dd4d-8bb0dc795fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "pd.DataFrame({'Id': test_generator.filenames,'Category': pred + 1}, index_col = \"Id\").to_csv(\"/content/drive/My Drive/CS412/Pred.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a40c249eb0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CS412/Pred.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'index_col'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWrwtYqcz-n9",
        "colab_type": "text"
      },
      "source": [
        "#Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3cKPDNiGhCM",
        "colab_type": "text"
      },
      "source": [
        "Hard Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWl7IKzkGSno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "labels.append(y1)\n",
        "labels.append(y2)\n",
        "labels.append(y3)\n",
        "\n",
        "import scipy\n",
        "# Ensemble with voting\n",
        "labels = np.array(labels)\n",
        "#labels = np.transpose(labels, (1, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXnDcNSOGgTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = scipy.stats.mode(labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDaN9IF8G2gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.squeeze(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JaIEIAaFMaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = test_generator.filenames\n",
        "for i in range(len(filenames)):\n",
        "  filenames[i] = filenames[i][2:len(filenames[i])-4]\n",
        "res = pd.DataFrame({'Id': filenames,'Category': labels + 1})\n",
        "res.set_index(\"Id\", inplace=True)\n",
        "res.to_csv(\"/content/drive/My Drive/CS412/Pred2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGLo5bPRGnuQ",
        "colab_type": "text"
      },
      "source": [
        "Soft Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z7bgeCRl7Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS = [tf.keras.models.load_model(\"/content/drive/My Drive/CS412/Models/resnetInception6820_model.h5\"), \n",
        "          tf.keras.models.load_model(\"/content/drive/My Drive/CS412/Models/densenet6889_model.h5\"), \n",
        "          tf.keras.models.load_model(\"/content/drive/My Drive/CS412/Models/xception_model_test.h5\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbMFOLh3JmAK",
        "colab_type": "code",
        "outputId": "828febd4-59d3-4196-d302-5762f66aecc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "MODELS[0].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 5, 5, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               196736    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 54,542,053\n",
            "Trainable params: 54,481,509\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k_LipzjJqpd",
        "colab_type": "code",
        "outputId": "1fabdb12-394b-4af1-8b27-83795773e5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "MODELS[1].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet201 (Model)          (None, 8, 8, 1920)        18321984  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 9605      \n",
            "=================================================================\n",
            "Total params: 18,331,589\n",
            "Trainable params: 17,724,677\n",
            "Non-trainable params: 606,912\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MrcK-7lJta3",
        "colab_type": "code",
        "outputId": "72249bf6-87bc-46df-dedc-e856dfe386f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "MODELS[2].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 8, 8, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                131136    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 20,992,941\n",
            "Trainable params: 10,147,797\n",
            "Non-trainable params: 10,845,144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3wC2xoblAW9",
        "colab_type": "code",
        "outputId": "fbaa5545-8901-43ed-fca8-187b9004729d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Predict labels with models\n",
        "labels = [] # this will contain predictions of each model individually.\n",
        "for model in MODELS:\n",
        "    predictionsWithProb = model.predict(test_generator, test_generator.samples // test_generator.batch_size+1, verbose=1)\n",
        "    predictedLabels = np.argmax(predictionsWithProb, axis=-1)\n",
        "\n",
        "    tuples = []\n",
        "    for p in range(0, len(predictedLabels)):\n",
        "      prediction = predictedLabels[p]\n",
        "      prob = predictionsWithProb[p][prediction] \n",
        "      tuples.append((prediction, prob))\n",
        "\n",
        "    labels.append(tuples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1826s 18s/step\n",
            "100/100 [==============================] - 57s 575ms/step\n",
            "100/100 [==============================] - 57s 572ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN_OPPOElcnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensemble with soft voting\n",
        "EnsembledPredictions = []\n",
        "for i in range(0, test_generator.n):\n",
        "  pred_1 = labels[0][i][0] # prediction\n",
        "  prob_1 = labels[0][i][1] # probability\n",
        "\n",
        "  pred_2 = labels[1][i][0]\n",
        "  prob_2 = labels[1][i][1]\n",
        "\n",
        "  pred_3 = labels[2][i][0]\n",
        "  prob_3 = labels[2][i][1]\n",
        "\n",
        "  ensembledPrediction = -1\n",
        "\n",
        "  if (pred_1 == pred_2 == pred_3):\n",
        "    ensembledPrediction = pred_1\n",
        "\n",
        "  elif (pred_1 == pred_2):\n",
        "    avg_prob = (prob_1 + prob_2) / 2\n",
        "\n",
        "    if prob_3 > avg_prob:\n",
        "      ensembledPrediction = pred_3\n",
        "    else:\n",
        "      ensembledPrediction = pred_1\n",
        "\n",
        "  elif (pred_1 == pred_3):\n",
        "    avg_prob = (prob_1 + prob_3) / 2\n",
        "\n",
        "    if prob_2 > avg_prob:\n",
        "      ensembledPrediction = pred_2\n",
        "    else:\n",
        "      ensembledPrediction = pred_1\n",
        "  \n",
        "  elif (pred_2 == pred_3):\n",
        "    avg_prob = (prob_2 + prob_3) / 2\n",
        "\n",
        "    if prob_1 > avg_prob:\n",
        "      ensembledPrediction = pred_1\n",
        "    else:\n",
        "      ensembledPrediction = pred_2\n",
        "\n",
        "  else: # all different predictions\n",
        "    dummy_prob_list = [prob_1, prob_2, prob_3]\n",
        "    dummy_pred_list = [pred_1, pred_2, pred_3]\n",
        "\n",
        "    maxProb = max(dummy_prob_list)\n",
        "    index = dummy_prob_list.index(maxProb)\n",
        "    ensembledPrediction = dummy_pred_list[index]\n",
        "\n",
        "  EnsembledPredictions.append(ensembledPrediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqtsm6cuvZj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using naive method to \n",
        "# perform conversion \n",
        "for i in range(0, len(EnsembledPredictions)): \n",
        "    EnsembledPredictions[i] = int(EnsembledPredictions[i]) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVaZ8HKvH9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame({'Id': filenames,'Category': EnsembledPredictions})\n",
        "res.set_index(\"Id\", inplace=True)\n",
        "res.to_csv(\"/content/drive/My Drive/CS412/Pred2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "604F1zPLGxWb",
        "colab_type": "text"
      },
      "source": [
        "Result of soft voting on validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRRTqTte7QX-",
        "colab_type": "code",
        "outputId": "604f17da-8796-4ba7-a4b3-b6cd8e2d6d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(classification_generator.classes, EnsembledPredictions))\n",
        "print('Classification Report')\n",
        "target_names = ['1', '2', '3', '4', '5']\n",
        "print(classification_report(classification_generator.classes, EnsembledPredictions, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[338  39  19   0  31]\n",
            " [ 24 360  14   1  28]\n",
            " [  0   5 308   0   6]\n",
            " [  1   0  18  61   6]\n",
            " [  4   6   9   0 239]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.79      0.85       427\n",
            "           2       0.88      0.84      0.86       427\n",
            "           3       0.84      0.97      0.90       319\n",
            "           4       0.98      0.71      0.82        86\n",
            "           5       0.77      0.93      0.84       258\n",
            "\n",
            "    accuracy                           0.86      1517\n",
            "   macro avg       0.88      0.85      0.85      1517\n",
            "weighted avg       0.87      0.86      0.86      1517\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}